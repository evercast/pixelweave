#version 450

#extension GL_EXT_shader_explicit_arithmetic_types : require
#extension GL_EXT_shader_explicit_arithmetic_types_int8 : require
#extension GL_EXT_shader_16bit_storage : require
#extension GL_EXT_shader_8bit_storage : require
#extension GL_EXT_scalar_block_layout : require
#extension GL_EXT_control_flow_attributes : require

#define LOCAL_WORKGROUP_SIZE_X 16
#define LOCAL_WORKGROUP_SIZE_Y 16

// When adding new pixel formats, fill the corresponding read<Subsample>From<Subsample> and readPixels function
// See PixelFormat.h
const uint PixelFormatInterleaved8BitUYVY = 0;
const uint PixelFormatInterleaved8BitBGRA = 1;
const uint PixelFormatInterleaved8BitRGBA = 2;
const uint PixelFormatPlanar8Bit420 = 3;
const uint PixelFormatPlanar8Bit422 = 4;
const uint PixelFormatPlanar8Bit444 = 5;
const uint PixelFormatPlanar8Bit420YV12 = 6;
const uint PixelFormatPlanar8Bit420NV12 = 7;
const uint PixelFormatInterleaved10BitUYVY = 8;
const uint PixelFormatInterleaved10BitRGB = 9;
const uint PixelFormatInterleaved12BitRGB = 10;
const uint PixelFormatPlanar10Bit420 = 11;
const uint PixelFormatPlanar10Bit422 = 12;
const uint PixelFormatPlanar10Bit444 = 13;

const uint SUBSAMPLE_TYPE_RGB = 0;
const uint SUBSAMPLE_TYPE_YUV420 = 1;
const uint SUBSAMPLE_TYPE_YUV422 = 2;
const uint SUBSAMPLE_TYPE_YUV444 = 3;

// Source picture properties (specialization constants for optimization)
layout (constant_id = 0) const uint SRC_PICTURE_WIDTH = 0;
layout (constant_id = 1) const uint SRC_PICTURE_HEIGHT = 0;
layout (constant_id = 2) const uint SRC_PICTURE_STRIDE = 0; // Luma stride in planar formats
layout (constant_id = 3) const uint SRC_PICTURE_CHROMA_WIDTH = 0;
layout (constant_id = 4) const uint SRC_PICTURE_CHROMA_HEIGHT = 0;
layout (constant_id = 5) const uint SRC_PICTURE_CHROMA_STRIDE = 0;
layout (constant_id = 6) const uint SRC_PICTURE_FORMAT = 0;
layout (constant_id = 7) const uint SRC_PICTURE_SUBSAMPLE_TYPE = 0;
layout (constant_id = 8) const uint SRC_PICTURE_U_OFFSET = 0;
layout (constant_id = 9) const uint SRC_PICTURE_V_OFFSET = 0;
layout (constant_id = 10) const uint SRC_PICTURE_BIT_DEPTH = 0;
layout (constant_id = 11) const uint SRC_PICTURE_BYTE_DEPTH = 0;

layout (constant_id = 12) const uint DST_PICTURE_WIDTH = 0;
layout (constant_id = 13) const uint DST_PICTURE_HEIGHT = 0;
layout (constant_id = 14) const uint DST_PICTURE_STRIDE = 0; // Luma stride in planar formats
layout (constant_id = 15) const uint DST_PICTURE_CHROMA_WIDTH = 0;
layout (constant_id = 16) const uint DST_PICTURE_CHROMA_HEIGHT = 0;
layout (constant_id = 17) const uint DST_PICTURE_CHROMA_STRIDE = 0;
layout (constant_id = 18) const uint DST_PICTURE_FORMAT = 0;
layout (constant_id = 19) const uint DST_PICTURE_SUBSAMPLE_TYPE = 0;
layout (constant_id = 20) const uint DST_PICTURE_U_OFFSET = 0;
layout (constant_id = 21) const uint DST_PICTURE_V_OFFSET = 0;
layout (constant_id = 22) const uint DST_PICTURE_BIT_DEPTH = 0;
layout (constant_id = 23) const uint DST_PICTURE_BYTE_DEPTH = 0;

const uint SRC_PICTURE_BLOCK_COUNT_X = (SRC_PICTURE_WIDTH + 1) / 2;
const uint SRC_PICTURE_BLOCK_COUNT_Y = (SRC_PICTURE_HEIGHT + 1) / 2;
const uint DST_PICTURE_BLOCK_COUNT_X = (DST_PICTURE_WIDTH + 1) / 2;
const uint DST_PICTURE_BLOCK_COUNT_Y = (DST_PICTURE_HEIGHT + 1) / 2;

const uvec2 BlockSize = uvec2(2,2);

layout(local_size_x = LOCAL_WORKGROUP_SIZE_X, local_size_y = LOCAL_WORKGROUP_SIZE_Y) in;

layout(scalar, set = 0, binding = 0) readonly buffer SrcPicture
{
    uint8_t[] pBuffer;
}
srcPicture;

layout(scalar, set = 0, binding = 0) readonly buffer SrcPicture16Bit
{
    uint16_t[] pBuffer;
}
srcPicture16;

layout(scalar, set = 0, binding = 0) readonly buffer SrcPicture32Bit
{
    uint32_t[] pBuffer;
}
srcPicture32;

#define SRC_PICTURE_BUFFER srcPicture.pBuffer
#define SRC_PICTURE_BUFFER16 srcPicture16.pBuffer
#define SRC_PICTURE_BUFFER32 srcPicture32.pBuffer

layout(scalar, set = 0, binding = 1) buffer DstPicture
{
    uint8_t[] pBuffer;
}
dstPicture;

layout(scalar, set = 0, binding = 1) buffer DstPicture16Bit
{
    uint16_t[] pBuffer;
}
dstPicture16;

layout(scalar, set = 0, binding = 1) buffer DstPicture32Bit
{
    uint32_t[] pBuffer;
}
dstPicture32;

#define DST_PICTURE_BUFFER dstPicture.pBuffer
#define DST_PICTURE_BUFFER16 dstPicture16.pBuffer
#define DST_PICTURE_BUFFER32 dstPicture32.pBuffer

struct YUV420Block {
    uint32_t[4] ySamples; // Top left, top right, bottom left, bottom right
    uint32_t uSample;
    uint32_t vSample;
};

struct YUV422Block {
    uint32_t[4] ySamples; // Top left, top right, bottom left, bottom right
    uint32_t[2] uSamples; // Top, bottom
    uint32_t[2] vSamples; // Top, bottom
};

struct YUV444Block {
    uint32_t[4] ySamples; // Top left, top right, bottom left, bottom right
    uint32_t[4] uSamples; // Top left, top right, bottom left, bottom right
    uint32_t[4] vSamples; // Top left, top right, bottom left, bottom right
};

struct RGBBlock {
    uint32_t[4] rSamples; // Top left, top right, bottom left, bottom right
    uint32_t[4] gSamples; // Top left, top right, bottom left, bottom right
    uint32_t[4] bSamples; // Top left, top right, bottom left, bottom right
};

// Read and conversion functions

// https://en.wikipedia.org/wiki/YCbCr
u32vec3 rgbToYUV(in u32vec3 rgb) {
    /*
        Inverse of the matrix below, which converts YUV legal -> RGB full
        doing the appropiate scaling. No need to scale with (235-16)/255.
        I have no idea of how the matrix below is derived, but somehow 
        it's everywhere. Hint? 1.1644 is 1.0 * (235-16)/255, but the others?
        Keep in mind glsl matrices are column-major
        
        [1.1644, 0.0, 1.7927],
        [1.1644, -0.2132, -0.5329],
        [1.1644, 2.1124, 0.0]
    */
    const mat3 rgbToYUVMatrix = mat3( 
        0.1825870759, -0.1006458962, 0.4392232994,
        0.6142312835, -0.3385774032, -0.3989573863,
        0.0619930457, 0.4392232994, -0.0402659131
    );
    const vec3 yuvLegal = rgbToYUVMatrix * vec3(rgb) + vec3(16.0, 128.0, 128.0);
    return u32vec3(clamp(round(yuvLegal), vec3(0.0), vec3(255.0)));
}

// In order to avoid unnecesary reads when using bilinear sampling
u32vec3 readPixelBase(uvec2 lumaCoords) {
    lumaCoords = clamp(lumaCoords, uvec2(0), uvec2(SRC_PICTURE_WIDTH - 1, SRC_PICTURE_HEIGHT - 1));
    u32vec3 result;
    switch (SRC_PICTURE_FORMAT) {
        case PixelFormatPlanar8Bit420:
        case PixelFormatPlanar8Bit420YV12:
        case PixelFormatPlanar8Bit420NV12: {
            // Read Y plane, this is the same across all planar and semi-planar formats
            const uint srcYBufferIndex = lumaCoords.y * SRC_PICTURE_STRIDE + lumaCoords.x;
            result.x = SRC_PICTURE_BUFFER[srcYBufferIndex];
            if (SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420 || SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420YV12) {
                // Fetch U, V samples from U, V planes
                const uvec2 chromaCoords = lumaCoords / BlockSize;
                const uint srcBufferUIndex = SRC_PICTURE_U_OFFSET + chromaCoords.y * SRC_PICTURE_CHROMA_STRIDE + chromaCoords.x;
                result.y = SRC_PICTURE_BUFFER[srcBufferUIndex];
                const uint srcBufferVIndex = SRC_PICTURE_V_OFFSET + chromaCoords.y * SRC_PICTURE_CHROMA_STRIDE + chromaCoords.x;
                result.z = SRC_PICTURE_BUFFER[srcBufferVIndex];
            } else if (SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420NV12) {
                // Fetch UV sample from UV plane
                const uvec2 chromaCoords = lumaCoords / BlockSize;
                const uint actualChromaStride = SRC_PICTURE_CHROMA_STRIDE * 2;
                const uint srcBufferUVIndex = SRC_PICTURE_U_OFFSET + chromaCoords.y * actualChromaStride + chromaCoords.x * 2;
                result.y = SRC_PICTURE_BUFFER[srcBufferUVIndex];
                result.z = SRC_PICTURE_BUFFER[srcBufferUVIndex + 1];
            }
        } break;
        case PixelFormatInterleaved8BitUYVY: {
            const uint verticalOffset = lumaCoords.y * SRC_PICTURE_STRIDE;
            const uint blockOffset = (lumaCoords.x / 2) * 4; // 4 channels per sample of which 2 are Y
            const uint ySampleOffset = 1 + (lumaCoords.x % 2) * 2; // 1 or 3 cause U Y V Y
            const uint srcYBufferIndex = verticalOffset + blockOffset + ySampleOffset;
            const uint srcUBufferIndex = verticalOffset + blockOffset;
            const uint srcVBufferIndex = srcUBufferIndex + 2;
            result = u32vec3(SRC_PICTURE_BUFFER[srcYBufferIndex], SRC_PICTURE_BUFFER[srcUBufferIndex], SRC_PICTURE_BUFFER[srcVBufferIndex]);
        } break;
        case PixelFormatInterleaved8BitBGRA: {
            const uint32_t pixelIndex = lumaCoords.y * SRC_PICTURE_STRIDE + lumaCoords.x * 4;
            i32vec3 rgbSamples = i32vec3(SRC_PICTURE_BUFFER[pixelIndex + 2], SRC_PICTURE_BUFFER[pixelIndex + 1], SRC_PICTURE_BUFFER[pixelIndex + 0]);
            result = rgbToYUV(rgbSamples);
        } break;
        case PixelFormatInterleaved8BitRGBA: {
            const uint32_t pixelIndex = lumaCoords.y * SRC_PICTURE_STRIDE + lumaCoords.x * 4;
            i32vec3 rgbSamples = i32vec3(SRC_PICTURE_BUFFER[pixelIndex + 0], SRC_PICTURE_BUFFER[pixelIndex + 1], SRC_PICTURE_BUFFER[pixelIndex + 2]);
            result = rgbToYUV(rgbSamples);
        } break;
        case PixelFormatInterleaved10BitUYVY: {
            const uint verticalOffset = lumaCoords.y * SRC_PICTURE_STRIDE / 4; // In words (32 bit)

            // Each 4 word block contains 6 pixels in total (6 y, 3uv)
            // Find the subLine (i.e. 4 word block) index
            const uint subLineIndex = (lumaCoords.x / 6) * 4;
            struct UYVYBlock {
                uint16_t y[6];
                uint16_t u[3];
                uint16_t v[3];
            };

            const uint32_t word0 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex];
            const uint32_t word1 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 1];
            const uint32_t word2 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 2];
            const uint32_t word3 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 3];

            UYVYBlock block;
            const uint32_t mask = 0x3FF;

            block.y[0] = uint16_t(word0 & (mask << 10));
            block.y[1] = uint16_t(word1 & mask);
            block.y[2] = uint16_t(word1 & (mask << 20));
            block.y[3] = uint16_t(word2 & (mask << 10));
            block.y[4] = uint16_t(word3 & mask);
            block.y[5] = uint16_t(word3 & (mask << 20));

            block.u[0] = uint16_t(word0 & (mask << 20));
            block.u[1] = uint16_t(word2 & mask);
            block.u[2] = uint16_t(word3 & (mask << 10));

            block.v[0] = uint16_t(word0 & mask);
            block.v[1] = uint16_t(word1 & (mask << 10));
            block.v[2] = uint16_t(word2 & (mask << 20));

            const uint yIndex = lumaCoords.x % 6;
            const uint uvIndex = lumaCoords.x % 3;

            result = u32vec3(block.y[yIndex], block.u[uvIndex], block.v[uvIndex]);
        } break;
        case PixelFormatInterleaved10BitRGB: {
            const uint verticalOffset = lumaCoords.y * SRC_PICTURE_STRIDE / 4; // Each pixel takes 4 bytes
            uint32_t word = SRC_PICTURE_BUFFER32[verticalOffset + lumaCoords.x * 4];
            u32vec3 pixel;

            pixel.r = uint32_t( (word & uint32_t(0x3F)) << 4 );
            pixel.r = pixel.r | uint32_t( (word & (uint32_t(0xF0) << 8)) >> 12 );

            pixel.g = uint32_t( (word & (uint32_t(0xFC) << 16) ) >> 18 );
            pixel.g = pixel.g | uint32_t( (word & (uint32_t(0x0F) << 8)) >> 2);

            pixel.b = uint32_t( (word & (uint32_t(0xFF) << 24)) >> 24 );
            pixel.b = pixel.b | uint32_t( (word & ( uint32_t(0x03) << 16 )) >> 8 );

            result = pixel;
        } break;
        case PixelFormatInterleaved12BitRGB: {
            const uint verticalOffset = lumaCoords.y * SRC_PICTURE_STRIDE / 4; // In words (32 bit)
            const uint subLineIndex = (lumaCoords.x / 9) * 4;            

            const uint pixelSubIndex = lumaCoords.x % 8;
            u32vec3 pixel;
            switch (pixelSubIndex) {
                case 0: {
                    const uint32_t word0 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex];
                    const uint32_t word1 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 1];
                    pixel = u32vec3(
                        ((word0 & (0xFF << 24)) >> 24) | ((word0 & (0x0F << 16)) >> 8),
                        ((word0 & (0xF0 << 16)) >> 12) | ((word0 & (0xFF << 8)) >> 4),
                        (word0 & 0xFF) | ((word1 & (0x0F << 24)) >> 16)
                    );
                } break;
                case 1: {
                    const uint32_t word1 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 1];
                    const uint32_t word2 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 2];
                    pixel = u32vec3(
                        ((word1 & (0xF0 << 24)) >> 28) | ((word1 & (0xFF << 16)) >> 12),
                        ((word1 & (0xFF << 8)) >> 8) | ((word1 & 0x0F) << 8),
                        ((word1 & (0xF0 << 0)) >> 4) | ((word2 & (0xFF << 24)) >> 20)
                    );
                } break;
                case 2: {
                    const uint32_t word2 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 2];
                    const uint32_t word3 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 3];
                    pixel = u32vec3(
                        ((word2 & (0xFF << 16)) >> 16) | ((word2 & (0x0F << 8)) >> 0),
                        ((word2 & (0xF0 << 8)) >> 12) | ((word2 & (0xFF << 0)) << 4),
                        ((word3 & (0xFF << 24)) >> 24) | ((word3 & (0x0F << 16)) >> 8)
                    );
                } break;
                case 3: {
                    const uint32_t word3 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 3];
                    const uint32_t word4 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 4];
                    pixel = u32vec3(
                        ((word3 & (0xF0 << 16)) >> 20) | ((word3 & (0xFF << 8)) >> 4),
                        (word3 & 0xFF) | ((word4 & (0x0F << 24)) >> 16),
                        ((word4 & (0xF0 << 24)) >> 16) | ((word4 & (0x0F << 20)) >> 28)
                    );
                } break;
                case 4: {
                    const uint32_t word4 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 4];
                    const uint32_t word5 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 5];
                    pixel = u32vec3(
                        ((word4 & (0xFF << 8)) >> 8) | ((word4 & (0x0F << 0)) << 8),
                        ((word4 & 0xF0) >> 4) | ((word5 & (0xFF << 24)) >> 24),
                        ((word5 & (0xFF << 16)) >> 16) | (word5 & (0x0F << 8))
                    );
                } break;
                case 5: {
                    const uint32_t word5 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 5];
                    const uint32_t word6 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 6];
                    pixel = u32vec3(
                        ((word5 & (0xF0 << 8)) >> 12) | ((word5 & 0xFF) << 4),
                        ((word6 & (0xFF << 24)) >> 24) | ((word6 & (0x0F << 16)) >> 8),
                        ((word6 & (0xF0 << 16)) >> 20) | ((word6 & (0xFF << 8)) >> 4)
                    );
                } break;
                case 6: {
                    const uint32_t word6 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 6];
                    const uint32_t word7 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 7];
                    pixel = u32vec3(
                        (word6 & 0xFF) | ((word7 & (0x0F << 24)) >> 16),
                        ((word7 & (0xFF << 16)) >> 12) | ((word7 & (0xF0 << 24)) >> 28),
                        ((word7 & (0xFF << 8)) >> 8) | ((word7 & 0x0F) << 8)
                    );
                } break;
                case 7: {
                    const uint32_t word7 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 7];
                    const uint32_t word8 = SRC_PICTURE_BUFFER32[verticalOffset + subLineIndex + 8];
                    pixel = u32vec3(
                        ((word8 & (0xFF << 24)) >> 12) | (word7 & 0xF0 >> 4),
                        ((word8 & (0xFF << 16)) >> 16) | (word8 & (0xF0 << 8)),
                        ((word8 & (0xF0 << 8)) >> 12) | ((word8 & 0xFF) << 4)
                    );
                } break;
            }
            result = pixel;
        } break;
    }

    return result;
}

u32vec3 ScaleBitDepth(const u32vec3 pixel) {
    const uint32_t maxValueDst = (1 << DST_PICTURE_BIT_DEPTH) - 1;
    const uint32_t maxValueSrc = (1 << SRC_PICTURE_BIT_DEPTH) - 1;
    const vec3 normalizedSrcPx = vec3(pixel) / maxValueSrc;
    return u32vec3(round(normalizedSrcPx * maxValueDst));
}

uint16_t SwapEndianess(const uint16_t source) {
    return (source >> 8) | (source << 8);
}

uint32_t SwapEndianess(const uint32_t source) {
    const uint32_t masked = ((source << 8) & uint32_t(0xFF00FF00) ) | ((source >> 8) & uint32_t(0xFF00FF)); 
    return (masked << 16) | (masked >> 16);
}

u32vec3 readPixel(uvec2 lumaCoords) {
    u32vec3 pixel = readPixelBase(lumaCoords);
    return ScaleBitDepth(pixel);
}

// Bilinear sampling

YUV420Block read420Bilinear(const uvec2 blockCoords) {
    YUV420Block result;
    const uvec2 srcImageSize = uvec2(SRC_PICTURE_WIDTH, SRC_PICTURE_HEIGHT);
    const uvec2 dstImageSize = uvec2(DST_PICTURE_WIDTH, DST_PICTURE_HEIGHT);
    u32vec3[4 * 4] sampledPixels;
    [[unroll]]
    for (int i = 0; i < BlockSize.x; i += 1) {
        [[unroll]]
        for (int j = 0; j < BlockSize.y; j += 1) {
            const uvec2 dstLumaCoords = blockCoords * BlockSize + uvec2(i,j);
            const vec2 pixelSize = vec2(1.0) / vec2(dstImageSize);
            const vec2 normalizedLumaCoords = dstLumaCoords / vec2(dstImageSize);
            const vec2 srcLumaCoords = normalizedLumaCoords * vec2(srcImageSize);
            const vec2 pixelDistance = fract(normalizedLumaCoords * srcImageSize);

            const vec2 topLeftCoord = srcLumaCoords;
            const vec2 topRightCoord = srcLumaCoords + vec2(pixelSize.x, 0.0);
            const vec2 bottomLeftCoord = srcLumaCoords + vec2(0.0, pixelSize.y);
            const vec2 bottomRightCoord = srcLumaCoords + pixelSize;

            const uint blockIndex = 4 * ((j * BlockSize.y) + i);
            sampledPixels[blockIndex] = readPixel((uvec2(topLeftCoord)));
            sampledPixels[blockIndex + 1] = readPixel(uvec2(topRightCoord));
            sampledPixels[blockIndex + 2] = readPixel(uvec2(bottomLeftCoord));
            sampledPixels[blockIndex + 3] = readPixel(uvec2(bottomRightCoord));

            // Interpolate and write Y sample
            const u32vec3 topLeftPixel = sampledPixels[blockIndex];
            const u32vec3 topRightPixel = sampledPixels[blockIndex + 1];
            const u32vec3 bottomLeftPixel = sampledPixels[blockIndex + 2];
            const u32vec3 bottomRightPixel = sampledPixels[blockIndex + 3];
            {
                vec4 ySamples = vec4(
                    float(topLeftPixel.x),
                    float(topRightPixel.x),
                    float(bottomLeftPixel.x),
                    float(bottomRightPixel.x)
                );
                const float topXInterp = mix(ySamples.x, ySamples.y, pixelDistance.x);
                const float bottomXInterp = mix(ySamples.z, ySamples.w, pixelDistance.x);
                result.ySamples[j * BlockSize.y + i] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
            }
        }
    }

    // Interpolate chroma samples, get average of all samples in the 4 by 4 block
    const u32vec3 topLeftPixel = (sampledPixels[4 * 0 + 0] + sampledPixels[4 * 1 + 0] + sampledPixels[4 * 2 + 0] +  sampledPixels[4 * 3 + 0]) / 4;
    const u32vec3 topRightPixel = (sampledPixels[4 * 0 + 1] + sampledPixels[4 * 1 + 1] + sampledPixels[4 * 2 + 1] +  sampledPixels[4 * 3 + 1]) / 4;
    const u32vec3 bottomLeftPixel = (sampledPixels[4 * 0 + 2] + sampledPixels[4 * 1 + 2] + sampledPixels[4 * 2 + 2] +  sampledPixels[4 * 3 + 2]) / 4;
    const u32vec3 bottomRightPixel = (sampledPixels[4 * 0 + 3] + sampledPixels[4 * 1 + 3] + sampledPixels[4 * 2 + 3] +  sampledPixels[4 * 3 + 3]) / 4;

    const vec2 normalizedChromaCoords = blockCoords / vec2(uvec2(DST_PICTURE_CHROMA_WIDTH, DST_PICTURE_CHROMA_HEIGHT));
    const vec2 pixelDistance = fract(normalizedChromaCoords * uvec2(SRC_PICTURE_CHROMA_WIDTH, SRC_PICTURE_CHROMA_HEIGHT));
    // Interpolate and write U sample
    {
        vec4 uSamples = vec4(
            float(topLeftPixel.y),
            float(topRightPixel.y),
            float(bottomLeftPixel.y),
            float(bottomRightPixel.y)
        );
        const float topXInterp = mix(uSamples.x, uSamples.y, pixelDistance.x);
        const float bottomXInterp = mix(uSamples.z, uSamples.w, pixelDistance.x);
        result.uSample = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
    }

    // Interpolate and write V sample
    {
        vec4 vSamples = vec4(
            float(topLeftPixel.z),
            float(topRightPixel.z),
            float(bottomLeftPixel.z),
            float(bottomRightPixel.z)
        );
        const float topXInterp = mix(vSamples.x, vSamples.y, pixelDistance.x);
        const float bottomXInterp = mix(vSamples.z, vSamples.w, pixelDistance.x);
        result.vSample = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
    }

    return result;
}

YUV422Block read422Bilinear(const uvec2 blockCoords) {
    YUV422Block result;
    const uvec2 srcImageSize = uvec2(SRC_PICTURE_WIDTH, SRC_PICTURE_HEIGHT);
    const uvec2 dstImageSize = uvec2(DST_PICTURE_WIDTH, DST_PICTURE_HEIGHT);
    u32vec3[4 * 4] sampledPixels;
    [[unroll]]
    for (int i = 0; i < BlockSize.x; i += 1) {
        [[unroll]]
        for (int j = 0; j < BlockSize.y; j += 1) {
            const uvec2 dstLumaCoords = blockCoords * BlockSize + uvec2(i,j);
            const vec2 pixelSize = vec2(1.0) / vec2(dstImageSize);
            const vec2 normalizedLumaCoords = dstLumaCoords / vec2(dstImageSize);
            const vec2 srcLumaCoords = normalizedLumaCoords * vec2(srcImageSize);
            const vec2 pixelDistance = fract(normalizedLumaCoords * srcImageSize);

            const vec2 topLeftCoord = srcLumaCoords;
            const vec2 topRightCoord = srcLumaCoords + vec2(pixelSize.x, 0.0);
            const vec2 bottomLeftCoord = srcLumaCoords + vec2(0.0, pixelSize.y);
            const vec2 bottomRightCoord = srcLumaCoords + pixelSize;

            const uint blockIndex = 4 * ((j * BlockSize.y) + i);
            sampledPixels[blockIndex] = readPixel(uvec2(topLeftCoord));
            sampledPixels[blockIndex + 1] = readPixel(uvec2(topRightCoord));
            sampledPixels[blockIndex + 2] = readPixel(uvec2(bottomLeftCoord));
            sampledPixels[blockIndex + 3] = readPixel(uvec2(bottomRightCoord));

            const u32vec3 topLeftPixel = sampledPixels[blockIndex];
            const u32vec3 topRightPixel = sampledPixels[blockIndex + 1];
            const u32vec3 bottomLeftPixel = sampledPixels[blockIndex + 2];
            const u32vec3 bottomRightPixel = sampledPixels[blockIndex + 3];
            // Interpolate and write Y sample
            {
                vec4 ySamples = vec4(
                    float(topLeftPixel.x),
                    float(topRightPixel.x),
                    float(bottomLeftPixel.x),
                    float(bottomRightPixel.x)
                );
                const float topXInterp = mix(ySamples.x, ySamples.y, pixelDistance.x);
                const float bottomXInterp = mix(ySamples.z, ySamples.w, pixelDistance.x);
                result.ySamples[j * BlockSize.y + i] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
            }
        }
    }

    [[unroll]]
    for (int j = 0; j < BlockSize.y; j += 1) {
        const uvec2 dstLumaCoords = blockCoords * BlockSize + uvec2(0,j);
        const vec2 normalizedLumaCoords = dstLumaCoords / vec2(dstImageSize);
        const vec2 pixelDistance = fract(normalizedLumaCoords * srcImageSize);

        // Get average of all samples in the 4 by 4 block (horizontally only, vertical resolution is preserved in 422 chroma)
        const uint leftBlockIndex = 4 * (j * BlockSize.y);
        const uint rightBlockIndex = leftBlockIndex + 4;
        const u32vec3 topLeftPixel = (sampledPixels[leftBlockIndex] + sampledPixels[rightBlockIndex + 0]) / 2;
        const u32vec3 topRightPixel = (sampledPixels[leftBlockIndex + 1] + sampledPixels[rightBlockIndex + 1]) / 2;
        const u32vec3 bottomLeftPixel = (sampledPixels[leftBlockIndex + 2] + sampledPixels[rightBlockIndex + 2]) / 2;
        const u32vec3 bottomRightPixel = (sampledPixels[leftBlockIndex + 3] + sampledPixels[rightBlockIndex + 3]) / 2;
        // Interpolate and write U sample
        {
            vec4 uSamples = vec4(
                float(topLeftPixel.y),
                float(topRightPixel.y),
                float(bottomLeftPixel.y),
                float(bottomRightPixel.y)
            );
            const float topXInterp = mix(uSamples.x, uSamples.y, pixelDistance.x);
            const float bottomXInterp = mix(uSamples.z, uSamples.w, pixelDistance.x);
            result.uSamples[j] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
        }

        // Interpolate and write V sample
        {
            vec4 vSamples = vec4(
                float(topLeftPixel.z),
                float(topRightPixel.z),
                float(bottomLeftPixel.z),
                float(bottomRightPixel.z)
            );
            const float topXInterp = mix(vSamples.x, vSamples.y, pixelDistance.x);
            const float bottomXInterp = mix(vSamples.z, vSamples.w, pixelDistance.x);
            result.vSamples[j] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
        }
    }
    return result;
}

YUV444Block read444Bilinear(const uvec2 blockCoords) {
    YUV444Block result;
    const uvec2 srcImageSize = uvec2(SRC_PICTURE_WIDTH, SRC_PICTURE_HEIGHT);
    const uvec2 dstImageSize = uvec2(DST_PICTURE_WIDTH, DST_PICTURE_HEIGHT);
    [[unroll]]
    for (int i = 0; i < BlockSize.x; i += 1) {
        [[unroll]]
        for (int j = 0; j < BlockSize.y; j += 1) {
            const uvec2 dstLumaCoords = blockCoords * BlockSize + uvec2(i,j);
            const vec2 pixelSize = vec2(1.0) / vec2(dstImageSize);
            const vec2 normalizedLumaCoords = dstLumaCoords / vec2(dstImageSize);
            const vec2 srcLumaCoords = normalizedLumaCoords * vec2(srcImageSize);
            const vec2 pixelDistance = fract(normalizedLumaCoords * srcImageSize);

            const vec2 topLeftCoord = srcLumaCoords;
            const vec2 topRightCoord = srcLumaCoords + vec2(pixelSize.x, 0.0);
            const vec2 bottomLeftCoord = srcLumaCoords + vec2(0.0, pixelSize.y);
            const vec2 bottomRightCoord = srcLumaCoords + pixelSize;

            u32vec3 topLeftPixel = readPixel(uvec2(topLeftCoord));
            u32vec3 topRightPixel = readPixel(uvec2(topRightCoord));
            u32vec3 bottomLeftPixel = readPixel(uvec2(bottomLeftCoord));
            u32vec3 bottomRightPixel = readPixel(uvec2(bottomRightCoord));
            
            // Interpolate and write Y sample
            {
                vec4 ySamples = vec4(
                    float(topLeftPixel.x),
                    float(topRightPixel.x),
                    float(bottomLeftPixel.x),
                    float(bottomRightPixel.x)
                );
                const float topXInterp = mix(ySamples.x, ySamples.y, pixelDistance.x);
                const float bottomXInterp = mix(ySamples.z, ySamples.w, pixelDistance.x);
                result.ySamples[j * BlockSize.y + i] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
            }

            // Interpolate and write U sample
            {
                vec4 uSamples = vec4(
                    float(topLeftPixel.y),
                    float(topRightPixel.y),
                    float(bottomLeftPixel.y),
                    float(bottomRightPixel.y)
                );
                const float topXInterp = mix(uSamples.x, uSamples.y, pixelDistance.x);
                const float bottomXInterp = mix(uSamples.z, uSamples.w, pixelDistance.x);
                result.uSamples[j * BlockSize.y + i] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
            }

            // Interpolate and write V sample
            {
                vec4 vSamples = vec4(
                    float(topLeftPixel.z),
                    float(topRightPixel.z),
                    float(bottomLeftPixel.z),
                    float(bottomRightPixel.z)
                );
                const float topXInterp = mix(vSamples.x, vSamples.y, pixelDistance.x);
                const float bottomXInterp = mix(vSamples.z, vSamples.w, pixelDistance.x);
                result.vSamples[j * BlockSize.y + i] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
            }
        }
    }
    return result;
}

// Write functions, to store into the result buffer
// For now, exclusively writes to YUV planar buffers

void write420Sample(const uvec2 blockCoords, in YUV420Block resultBlock) {
    [[unroll]]
    for (uint y = 0; y < 2; y += 1) {
        const uvec2 lumaCoords = uvec2(blockCoords.x * 2, blockCoords.y * 2 + y);
        if (lumaCoords.x < DST_PICTURE_WIDTH && lumaCoords.y < DST_PICTURE_HEIGHT) {
            const uint dstYBufferIndex = lumaCoords.y * DST_PICTURE_STRIDE / DST_PICTURE_BYTE_DEPTH + lumaCoords.x;
            const uint32_t firstSample = resultBlock.ySamples[y * 2];
            const uint32_t secondSample = resultBlock.ySamples[y * 2 + 1];
            if (DST_PICTURE_BIT_DEPTH == 10) {
                DST_PICTURE_BUFFER16[dstYBufferIndex] = uint16_t(firstSample);
                DST_PICTURE_BUFFER16[dstYBufferIndex + 1] = uint16_t(secondSample);
            }
            else {
                DST_PICTURE_BUFFER[dstYBufferIndex] = uint8_t(firstSample);
                DST_PICTURE_BUFFER[dstYBufferIndex + 1] = uint8_t(secondSample);
            }
        }
    }

    const uvec2 chromaCoords = uvec2(blockCoords.x, blockCoords.y);
    if (chromaCoords.x < DST_PICTURE_CHROMA_WIDTH && chromaCoords.y < DST_PICTURE_CHROMA_HEIGHT) {
        const uint dstUBufferIndex = DST_PICTURE_U_OFFSET / DST_PICTURE_BYTE_DEPTH + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE / DST_PICTURE_BYTE_DEPTH + chromaCoords.x;

        if (DST_PICTURE_BIT_DEPTH == 10) {
            DST_PICTURE_BUFFER16[dstUBufferIndex] = uint16_t(resultBlock.uSample);
        } else {
            DST_PICTURE_BUFFER[dstUBufferIndex] = uint8_t(resultBlock.uSample);
        }

        const uint dstVBufferIndex = DST_PICTURE_V_OFFSET / DST_PICTURE_BYTE_DEPTH + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE / DST_PICTURE_BYTE_DEPTH + chromaCoords.x;
        if (DST_PICTURE_BIT_DEPTH == 10) {
            DST_PICTURE_BUFFER16[dstVBufferIndex] = uint16_t(resultBlock.vSample);
        } else {
            DST_PICTURE_BUFFER[dstVBufferIndex] = uint8_t(resultBlock.vSample);
        }
    }
}

void write422Sample(const uvec2 blockCoords, in YUV422Block resultBlock) {
    [[unroll]]
    for (uint y = 0; y < 2; y += 1) {
        const uvec2 lumaCoords = uvec2(blockCoords.x * 2, blockCoords.y * 2 + y);
        if (lumaCoords.x < DST_PICTURE_WIDTH && lumaCoords.y < DST_PICTURE_HEIGHT) {
            const uint dstYBufferIndex = lumaCoords.y * DST_PICTURE_STRIDE / DST_PICTURE_BYTE_DEPTH + lumaCoords.x;
            if (DST_PICTURE_BIT_DEPTH == 10) {
                DST_PICTURE_BUFFER16[dstYBufferIndex] = uint16_t(resultBlock.ySamples[y * 2]);
                DST_PICTURE_BUFFER16[dstYBufferIndex + 1] = uint16_t(resultBlock.ySamples[y * 2 + 1]);
            } else {
                DST_PICTURE_BUFFER[dstYBufferIndex] = uint8_t(resultBlock.ySamples[y * 2]);
                DST_PICTURE_BUFFER[dstYBufferIndex + 1] = uint8_t(resultBlock.ySamples[y * 2 + 1]);
            }
        }
    }

    [[unroll]]
    for (uint y = 0; y < 2; y += 1) {
        const uvec2 chromaCoords = uvec2(blockCoords.x, blockCoords.y * 2 + y);
        if (chromaCoords.x < DST_PICTURE_CHROMA_WIDTH && chromaCoords.y < DST_PICTURE_CHROMA_HEIGHT) {
            const uint dstUBufferIndex = DST_PICTURE_U_OFFSET / DST_PICTURE_BYTE_DEPTH + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE / DST_PICTURE_BYTE_DEPTH + chromaCoords.x;
            if (DST_PICTURE_BIT_DEPTH == 10) {
                DST_PICTURE_BUFFER16[dstUBufferIndex] = uint16_t(resultBlock.uSamples[y]);
            } else {
                DST_PICTURE_BUFFER[dstUBufferIndex] = uint8_t(resultBlock.uSamples[y]);
            }
        }
    }

    [[unroll]]
    for (uint y = 0; y < 2; y += 1) {
        const uvec2 chromaCoords = uvec2(blockCoords.x, blockCoords.y * 2 + y);
        if (chromaCoords.x < DST_PICTURE_CHROMA_WIDTH && chromaCoords.y < DST_PICTURE_CHROMA_HEIGHT) {
            const uint dstVBufferIndex = DST_PICTURE_V_OFFSET / DST_PICTURE_BYTE_DEPTH + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE / DST_PICTURE_BYTE_DEPTH + chromaCoords.x;
            if (DST_PICTURE_BIT_DEPTH == 10) {
                DST_PICTURE_BUFFER16[dstVBufferIndex] = uint16_t(resultBlock.vSamples[y]);
            } else {
                DST_PICTURE_BUFFER[dstVBufferIndex] = uint8_t(resultBlock.vSamples[y]);
            }
        }
    }
}

void write444Sample(const uvec2 blockCoords, in YUV444Block resultBlock) {
    [[unroll]]
    for (int i = 0; i < 2; i += 1) {
        [[unroll]]
        for (int j = 0; j < 2; j += 1) {
            uvec2 lumaCoords = uvec2(blockCoords.x * 2 + i, blockCoords.y * 2 + j);
            if (lumaCoords.x < DST_PICTURE_WIDTH && lumaCoords.y < DST_PICTURE_HEIGHT) {
                const uint dstYBufferIndex = lumaCoords.y * DST_PICTURE_STRIDE / DST_PICTURE_BYTE_DEPTH + lumaCoords.x;
                if (DST_PICTURE_BIT_DEPTH == 10) {
                    DST_PICTURE_BUFFER16[dstYBufferIndex] = uint16_t(resultBlock.ySamples[j * 2 + i]);
                } else {
                    DST_PICTURE_BUFFER[dstYBufferIndex] = uint8_t(resultBlock.ySamples[j * 2 + i]);
                }
            }
        }
    }

    [[unroll]]
    for (int i = 0; i < 2; i += 1) {
        [[unroll]]
        for (int j = 0; j < 2; j += 1) {
            const uvec2 chromaCoords = uvec2(blockCoords.x * 2 + i, blockCoords.y * 2 + j);
            if (chromaCoords.x < DST_PICTURE_WIDTH && chromaCoords.y < DST_PICTURE_HEIGHT) {
                const uint dstUBufferIndex = DST_PICTURE_U_OFFSET / DST_PICTURE_BYTE_DEPTH + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE / DST_PICTURE_BYTE_DEPTH + chromaCoords.x;
                if (DST_PICTURE_BIT_DEPTH == 10) {
                    DST_PICTURE_BUFFER16[dstUBufferIndex] = uint16_t(resultBlock.uSamples[j * 2 + i]);
                } else {
                    DST_PICTURE_BUFFER[dstUBufferIndex] = uint8_t(resultBlock.uSamples[j * 2 + i]);
                }
            }
        }
    }

    [[unroll]]
    for (int i = 0; i < 2; i += 1) {
        [[unroll]]
        for (int j = 0; j < 2; j += 1) {
            const uvec2 chromaCoords = uvec2(blockCoords.x * 2 + i, blockCoords.y * 2 + j);
            if (chromaCoords.x < DST_PICTURE_WIDTH && chromaCoords.y < DST_PICTURE_HEIGHT) {
                const uint dstVBufferIndex = DST_PICTURE_V_OFFSET / DST_PICTURE_BYTE_DEPTH + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE / DST_PICTURE_BYTE_DEPTH + chromaCoords.x;
                if (DST_PICTURE_BIT_DEPTH == 10) {
                    DST_PICTURE_BUFFER16[dstVBufferIndex] = uint16_t(resultBlock.vSamples[j * 2 + i]);
                } else {
                    DST_PICTURE_BUFFER[dstVBufferIndex] = uint8_t(resultBlock.vSamples[j * 2 + i]);
                }
            }
        }
    }
}

/*
    Workflow:
        -> The shader will read (and convert) any format passed to it. Meaning results always are in the target subsample format. Regardless of input.
            -> If the source and target subsampling doesn't match, the shader will read as many samples as necessary to go from source subsample -> dst subsample
                -> The function read422Sample will convert whatever the current input format is to SubsampleType
                -> It will rely on read422From422 and friends to get the values out of the buffer using the actual source type
                -> When the subsample method doesn't match it will convert it (example: going from RGB to 444 by converting via YUV matrix)
            -> Some filtering may be used by calling read422SampleNearest and friends, if necessary
                -> When using bilinear filtering, custom read methods will be used (see the readPixel function)
        -> After everything is read, the shader will now have a block of samples in the same subsampling method as the dest. buffer
        -> The shader will now write into the dst buffer depending on its format (see write420Sample, write422Sample, etc)

        Examples:
            - No subsampling conversion:
                read422SampleNearest()
                    read422Sample()
                        read422SampleFrom422Buffer() 
                write422Sample()
            - From 420 buffer to 422 buffer:
                read422SampleBilinear()
                    readPixel() <- x16 times
                    pixels are interpolated
                write422Sample()
*/
void main() {
    const uvec2 blockCoords = gl_GlobalInvocationID.xy;
    if (DST_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_RGB) {
        // TODO
    } else if (DST_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV420) {
        YUV420Block resultBlock;
        resultBlock = read420Bilinear(blockCoords);
        write420Sample(blockCoords, resultBlock);
    } else if (DST_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV422) {
        YUV422Block resultBlock;
        resultBlock = read422Bilinear(blockCoords);
        write422Sample(blockCoords, resultBlock);
    } else if (DST_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV444) {
        YUV444Block resultBlock;
        resultBlock = read444Bilinear(blockCoords);
        write444Sample(blockCoords, resultBlock);
    }
}