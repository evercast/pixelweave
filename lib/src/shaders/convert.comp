#version 450

#extension GL_EXT_shader_explicit_arithmetic_types : require
#extension GL_EXT_shader_explicit_arithmetic_types_int8 : require
#extension GL_EXT_shader_16bit_storage : require
#extension GL_EXT_shader_8bit_storage : require
#extension GL_EXT_scalar_block_layout : require
#extension GL_EXT_control_flow_attributes : require

#define LOCAL_WORKGROUP_SIZE_X 16
#define LOCAL_WORKGROUP_SIZE_Y 16

// When adding new pixel formats, fill the corresponding read<Subsample>From<Subsample> and readPixels function
// See PixelFormat.h
const uint PixelFormatInterleaved8BitUYVY = 0;
const uint PixelFormatInterleaved8BitBGRA = 1;
const uint PixelFormatInterleaved8BitRGBA = 2;
const uint PixelFormatPlanar8Bit420 = 3;
const uint PixelFormatPlanar8Bit422 = 4;
const uint PixelFormatPlanar8Bit444 = 5;
const uint PixelFormatPlanar8Bit420YV12 = 6;
const uint PixelFormatPlanar8Bit420NV12 = 7;

const uint SUBSAMPLE_TYPE_RGB = 0;
const uint SUBSAMPLE_TYPE_YUV420 = 1;
const uint SUBSAMPLE_TYPE_YUV422 = 2;
const uint SUBSAMPLE_TYPE_YUV444 = 3;

// Source picture properties (specialization constants for optimization)
layout (constant_id = 0) const uint SRC_PICTURE_WIDTH = 0;
layout (constant_id = 1) const uint SRC_PICTURE_HEIGHT = 0;
layout (constant_id = 2) const uint SRC_PICTURE_STRIDE = 0; // Luma stride in planar formats
layout (constant_id = 3) const uint SRC_PICTURE_CHROMA_WIDTH = 0;
layout (constant_id = 4) const uint SRC_PICTURE_CHROMA_HEIGHT = 0;
layout (constant_id = 5) const uint SRC_PICTURE_CHROMA_STRIDE = 0;
layout (constant_id = 6) const uint SRC_PICTURE_FORMAT = 0;
layout (constant_id = 7) const uint SRC_PICTURE_SUBSAMPLE_TYPE = 0;
layout (constant_id = 8) const uint SRC_PICTURE_U_OFFSET = 0;
layout (constant_id = 9) const uint SRC_PICTURE_V_OFFSET = 0;

layout (constant_id = 10) const uint DST_PICTURE_WIDTH = 0;
layout (constant_id = 11) const uint DST_PICTURE_HEIGHT = 0;
layout (constant_id = 12) const uint DST_PICTURE_STRIDE = 0; // Luma stride in planar formats
layout (constant_id = 13) const uint DST_PICTURE_CHROMA_WIDTH = 0;
layout (constant_id = 14) const uint DST_PICTURE_CHROMA_HEIGHT = 0;
layout (constant_id = 15) const uint DST_PICTURE_CHROMA_STRIDE = 0;
layout (constant_id = 16) const uint DST_PICTURE_FORMAT = 0;
layout (constant_id = 17) const uint DST_PICTURE_SUBSAMPLE_TYPE = 0;
layout (constant_id = 18) const uint DST_PICTURE_U_OFFSET = 0;
layout (constant_id = 19) const uint DST_PICTURE_V_OFFSET = 0;

const uint SRC_PICTURE_BLOCK_COUNT_X = (SRC_PICTURE_WIDTH + 1) / 2;
const uint SRC_PICTURE_BLOCK_COUNT_Y = (SRC_PICTURE_HEIGHT + 1) / 2;
const uint DST_PICTURE_BLOCK_COUNT_X = (DST_PICTURE_WIDTH + 1) / 2;
const uint DST_PICTURE_BLOCK_COUNT_Y = (DST_PICTURE_HEIGHT + 1) / 2;

const uvec2 BlockSize = uvec2(2,2);

const bool needsScaling = SRC_PICTURE_WIDTH != DST_PICTURE_WIDTH || SRC_PICTURE_HEIGHT != DST_PICTURE_HEIGHT;

layout(local_size_x = LOCAL_WORKGROUP_SIZE_X, local_size_y = LOCAL_WORKGROUP_SIZE_Y) in;

layout(scalar, set = 0, binding = 0) readonly buffer SrcPicture
{
    uint8_t[] pBuffer;
}
srcPicture;

layout(scalar, set = 0, binding = 1) buffer DstPicture
{
    uint8_t[] pBuffer;
}
dstPicture;

struct YUV420Block {
    uint32_t[4] ySamples; // Top left, top right, bottom left, bottom right
    uint32_t uSample;
    uint32_t vSample;
};

struct YUV422Block {
    uint32_t[4] ySamples; // Top left, top right, bottom left, bottom right
    uint32_t[2] uSamples; // Top, bottom
    uint32_t[2] vSamples; // Top, bottom
};

struct YUV444Block {
    uint32_t[4] ySamples; // Top left, top right, bottom left, bottom right
    uint32_t[4] uSamples; // Top left, top right, bottom left, bottom right
    uint32_t[4] vSamples; // Top left, top right, bottom left, bottom right
};

struct RGBBlock {
    uint32_t[4] rSamples; // Top left, top right, bottom left, bottom right
    uint32_t[4] gSamples; // Top left, top right, bottom left, bottom right
    uint32_t[4] bSamples; // Top left, top right, bottom left, bottom right
};

// Block conversion helpers
YUV420Block convert422To420(in YUV422Block source) {
    YUV420Block result;
    [[unroll]]
    for (uint i = 0; i < BlockSize.x * BlockSize.y; i += 1) {
        result.ySamples[i] = source.ySamples[i];
    }
    result.uSample = (source.uSamples[0] + source.uSamples[1]) / 2;
    result.vSample = (source.vSamples[0] + source.vSamples[1]) / 2;
    return result;
}

YUV420Block convert444To420(in YUV444Block source) {
    YUV420Block result;
    [[unroll]]
    for (uint i = 0; i < BlockSize.x * BlockSize.y; i += 1) {
        result.ySamples[i] = source.ySamples[i];
    }
    result.uSample = (source.uSamples[0] + source.uSamples[1] + source.uSamples[2] + source.uSamples[3]) / 4;
    result.vSample = (source.vSamples[0] + source.vSamples[1] + source.vSamples[2] + source.vSamples[3]) / 4;
    return result;
}

YUV422Block convert420To422(in YUV420Block source) {
    YUV422Block result;
    [[unroll]]
    for (uint i = 0; i < BlockSize.x * BlockSize.y; i += 1) {
        result.ySamples[i] = source.ySamples[i];
    }
    [[unroll]]
    for (uint i = 0; i < 2; i += 1) {
        result.uSamples[i] = source.uSample;
        result.vSamples[i] = source.vSample;
    }
    return result;
}

YUV422Block convert444To422(in YUV444Block source) {
    YUV422Block result;
    [[unroll]]
    for (uint i = 0; i < BlockSize.x * BlockSize.y; i += 1) {
        result.ySamples[i] = source.ySamples[i];
    }
    result.uSamples[0] = (source.uSamples[0] + source.uSamples[1]) / 2;
    result.uSamples[1] = (source.uSamples[2] + source.uSamples[3]) / 2;
    result.vSamples[0] = (source.vSamples[0] + source.vSamples[1]) / 2;
    result.vSamples[1] = (source.vSamples[2] + source.vSamples[3]) / 2;
    return result;
}

YUV444Block convert420To444(in YUV420Block source) {
    YUV444Block result;
    [[unroll]]
    for (uint i = 0; i < BlockSize.x * BlockSize.y; i += 1) {
        result.ySamples[i] = source.ySamples[i];
        result.uSamples[i] = source.uSample;
        result.vSamples[i] = source.vSample;
    }
    return result;
}

YUV444Block convert422To444(in YUV422Block source) {
    YUV444Block result;
    [[unroll]]
    for (uint i = 0; i < BlockSize.x * BlockSize.y; i += 1) {
        result.ySamples[i] = source.ySamples[i];
        result.uSamples[i] = source.uSamples[i/2];
        result.vSamples[i] = source.vSamples[i/2];
    }
    return result;
}

// https://www.itu.int/rec/R-REC-BT.709/es
u32vec3 rgbToYUV(in i32vec3 rgb) {
    u32vec3 yuv;
    // Since we're doing math in 2 ^ 16 range
    const int32_t blackOffset = int32_t((16.0 / 255.0) * float(1 << 16));
    const int32_t chromaOffset = int32_t((128.0 / 255.0) * float(1 << 16));
    // In BT709, limited range (16-235)
    yuv.x = clamp((47 * rgb.r + 157 * rgb.g + 16 * rgb.b + blackOffset) >> 8, 0, 255);
    yuv.y = clamp((-22 * rgb.r - 74 * rgb.g + 95 * rgb.b  + chromaOffset) >> 8, 0, 255);
    yuv.z = clamp((135 * rgb.r - 122 * rgb.g - 12 * rgb.b + chromaOffset) >> 8, 0, 255);
    return yuv;
}

YUV444Block convertRGBTo444(in RGBBlock source) {
    YUV444Block result;
    [[unroll]]
    for (uint i = 0; i < BlockSize.x * BlockSize.y; i += 1) {
        const int32_t r = int32_t(source.rSamples[i]);
        const int32_t g = int32_t(source.gSamples[i]);
        const int32_t b = int32_t(source.bSamples[i]);
        const u32vec3 yuv = rgbToYUV(i32vec3(r,g,b));
        result.ySamples[i] = yuv.x;
        result.uSamples[i] = yuv.y;
        result.vSamples[i] = yuv.z;
    }
    return result;
}

// Read functions, to retrieve and convert samples

YUV420Block read420SampleFrom420Buffer(const uvec2 blockCoords) {
    YUV420Block resultBlock;
    // Read Y block (2 samples up, 2 samples down)
    if (SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420 || SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420YV12 || SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420NV12) {
        [[unroll]]
        for (uint y = 0; y < 2; y += 1) {
            uvec2 lumaCoords = uvec2(blockCoords.x * 2, blockCoords.y * 2 + y);
            lumaCoords = clamp(lumaCoords, uvec2(0), uvec2(SRC_PICTURE_WIDTH - 1, SRC_PICTURE_HEIGHT - 1));
            const uint srcBufferIndex = lumaCoords.y * SRC_PICTURE_STRIDE + lumaCoords.x;
            resultBlock.ySamples[y * 2] = srcPicture.pBuffer[srcBufferIndex];
            resultBlock.ySamples[y * 2 + 1] = srcPicture.pBuffer[srcBufferIndex + 1];
        }
    }
    
    // Read UV values
    const uvec2 chromaCoords = clamp(blockCoords, uvec2(0), uvec2(SRC_PICTURE_CHROMA_WIDTH - 1, SRC_PICTURE_CHROMA_HEIGHT - 1));
    if (SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420 || SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420YV12) {
        // Read U value for the block
        const uint srcBufferUIndex = SRC_PICTURE_U_OFFSET + chromaCoords.y * SRC_PICTURE_CHROMA_STRIDE + chromaCoords.x;
        resultBlock.uSample = srcPicture.pBuffer[srcBufferUIndex];
        // Read V value for the block
        const uint srcBufferVIndex = SRC_PICTURE_V_OFFSET + chromaCoords.y * SRC_PICTURE_CHROMA_STRIDE + chromaCoords.x;
        resultBlock.vSample = srcPicture.pBuffer[srcBufferVIndex];
    } else if (SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420NV12) {
        // U offset is UV offset for this format
        const uint actualChromaStride = SRC_PICTURE_CHROMA_STRIDE * 2;
        const uint srcBufferUVIndex = SRC_PICTURE_U_OFFSET + chromaCoords.y * actualChromaStride + chromaCoords.x * 2;
        resultBlock.uSample = srcPicture.pBuffer[srcBufferUVIndex];
        resultBlock.vSample = srcPicture.pBuffer[srcBufferUVIndex + 1];
    }
    return resultBlock;
}

YUV422Block read422SampleFrom422Buffer(const uvec2 blockCoords) {
    if (SRC_PICTURE_FORMAT == PixelFormatInterleaved8BitUYVY) {
        YUV422Block resultBlock;
        [[unroll]]
        for (uint y = 0; y < 2; y += 1) {
            uvec2 lumaCoords = uvec2(blockCoords.x * 2, blockCoords.y * 2 + y);
            lumaCoords = clamp(lumaCoords, uvec2(0), uvec2(SRC_PICTURE_WIDTH - 1, SRC_PICTURE_HEIGHT - 1));
            const uint channelsPerWord = 4;
            const uint srcBufferIndex = lumaCoords.y * SRC_PICTURE_STRIDE + (lumaCoords.x * channelsPerWord / 2);
            resultBlock.uSamples[y] = srcPicture.pBuffer[srcBufferIndex + 0];
            resultBlock.ySamples[y * 2] = srcPicture.pBuffer[srcBufferIndex + 1];
            resultBlock.vSamples[y] = srcPicture.pBuffer[srcBufferIndex + 2];
            resultBlock.ySamples[y * 2 + 1] = srcPicture.pBuffer[srcBufferIndex + 3];
        }
        return resultBlock;
    }
}

YUV444Block read444SampleFrom444Buffer(const uvec2 blockCoords) {
    if (SRC_PICTURE_FORMAT == PixelFormatInterleaved8BitBGRA) {
        RGBBlock rgbBlock;
        [[unroll]]
        for (int i = 0; i < BlockSize.x; i += 1) {
            for (int j = 0; j < BlockSize.y; j += 1) {
                uvec2 lumaCoords = uvec2(blockCoords.x * 2 + i, blockCoords.y * 2 + j);
                lumaCoords = clamp(lumaCoords, uvec2(0), uvec2(SRC_PICTURE_WIDTH - 1, SRC_PICTURE_HEIGHT - 1));
                const uint32_t pixelIndex = lumaCoords.y * SRC_PICTURE_STRIDE + lumaCoords.x * 4;
                const uint32_t inBlockIndex = j * 2 + i;
                rgbBlock.rSamples[inBlockIndex] = srcPicture.pBuffer[pixelIndex + 2];
                rgbBlock.gSamples[inBlockIndex] = srcPicture.pBuffer[pixelIndex + 1];
                rgbBlock.bSamples[inBlockIndex] = srcPicture.pBuffer[pixelIndex + 0];
            }
        }
        return convertRGBTo444(rgbBlock);
    } else if (SRC_PICTURE_FORMAT == PixelFormatInterleaved8BitRGBA) {
        RGBBlock rgbBlock;
        [[unroll]]
        for (int i = 0; i < BlockSize.x; i += 1) {
            for (int j = 0; j < BlockSize.y; j += 1) {
                uvec2 lumaCoords = uvec2(blockCoords.x * 2 + i, blockCoords.y * 2 + j);
                lumaCoords = clamp(lumaCoords, uvec2(0), uvec2(SRC_PICTURE_WIDTH - 1, SRC_PICTURE_HEIGHT - 1));
                const uint32_t pixelIndex = lumaCoords.y * SRC_PICTURE_STRIDE + lumaCoords.x * 4;
                const uint32_t inBlockIndex = j * 2 + i;
                rgbBlock.rSamples[inBlockIndex] = srcPicture.pBuffer[pixelIndex + 0];
                rgbBlock.gSamples[inBlockIndex] = srcPicture.pBuffer[pixelIndex + 1];
                rgbBlock.bSamples[inBlockIndex] = srcPicture.pBuffer[pixelIndex + 2];
            }
        }
        return convertRGBTo444(rgbBlock);
    }
}

YUV420Block read420Sample(const uvec2 blockCoords) {
    if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_RGB) {
        YUV444Block source = read444SampleFrom444Buffer(blockCoords);
        return convert444To420(source);
    } else if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV420) {
        return read420SampleFrom420Buffer(blockCoords);
    } else if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV422) {
        YUV422Block source = read422SampleFrom422Buffer(blockCoords);
        return convert422To420(source);
    } else if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV444) {
        YUV444Block source = read444SampleFrom444Buffer(blockCoords);
        return convert444To420(source);
    }
}

YUV422Block read422Sample(const uvec2 blockCoords) {
    if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_RGB) {
        YUV444Block source = read444SampleFrom444Buffer(blockCoords);
        return convert444To422(source);
    } else if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV420) {
        YUV420Block source = read420SampleFrom420Buffer(blockCoords);
        return convert420To422(source);
    } else if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV422) {
        return read422SampleFrom422Buffer(blockCoords);
    } else if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV444) {
        YUV444Block source = read444SampleFrom444Buffer(blockCoords);
        return convert444To422(source);
    }
}

YUV444Block read444Sample(const uvec2 blockCoords) {
    if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_RGB) {
        return read444SampleFrom444Buffer(blockCoords);
    } else if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV420) {
        YUV420Block source = read420SampleFrom420Buffer(blockCoords);
        return convert420To444(source);
    } else if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV422) {
        YUV422Block source = read422SampleFrom422Buffer(blockCoords);
        return convert422To444(source);
    } else if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV444) {
        return read444SampleFrom444Buffer(blockCoords);
    }
}

// In order to avoid unnecesary reads when using bilinear sampling
u32vec3 readPixel(uvec2 lumaCoords) {
    lumaCoords = clamp(lumaCoords, uvec2(0), uvec2(SRC_PICTURE_WIDTH - 1, SRC_PICTURE_HEIGHT - 1));
    if (SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420 || SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420YV12 || SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420NV12) {
        u32vec3 result;
        // Read Y plane, this is the same across all planar and semi-planar formats
        const uint srcYBufferIndex = lumaCoords.y * SRC_PICTURE_STRIDE + lumaCoords.x;
        result.x = srcPicture.pBuffer[srcYBufferIndex];
        if (SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420 || SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420YV12) {
            // Fetch U, V samples from U, V planes
            const uvec2 chromaCoords = lumaCoords / BlockSize;
            const uint srcBufferUIndex = SRC_PICTURE_U_OFFSET + chromaCoords.y * SRC_PICTURE_CHROMA_STRIDE + chromaCoords.x;
            result.y = srcPicture.pBuffer[srcBufferUIndex];
            const uint srcBufferVIndex = SRC_PICTURE_V_OFFSET + chromaCoords.y * SRC_PICTURE_CHROMA_STRIDE + chromaCoords.x;
            result.z = srcPicture.pBuffer[srcBufferVIndex];
        } else if (SRC_PICTURE_FORMAT == PixelFormatPlanar8Bit420NV12) {
            // Fetch UV sample from UV plane
            const uvec2 chromaCoords = lumaCoords / BlockSize;
            const uint actualChromaStride = SRC_PICTURE_CHROMA_STRIDE * 2;
            const uint srcBufferUVIndex = SRC_PICTURE_U_OFFSET + chromaCoords.y * actualChromaStride + chromaCoords.x * 2;
            result.y = srcPicture.pBuffer[srcBufferUVIndex];
            result.z = srcPicture.pBuffer[srcBufferUVIndex + 1];
        }
        return result;
    } else if (SRC_PICTURE_FORMAT == PixelFormatInterleaved8BitUYVY) {
        const uint verticalOffset = lumaCoords.y * SRC_PICTURE_STRIDE;
        const uint blockOffset = (lumaCoords.x / 2) * 4; // 4 channels per sample of which 2 are Y
        const uint ySampleOffset = 1 + (lumaCoords.x % 2) * 2; // 1 or 3 cause U Y V Y
        const uint srcYBufferIndex = verticalOffset + blockOffset + ySampleOffset;
        const uint srcUBufferIndex = verticalOffset + blockOffset;
        const uint srcVBufferIndex = srcUBufferIndex + 2;
        return u32vec3(srcPicture.pBuffer[srcYBufferIndex], srcPicture.pBuffer[srcUBufferIndex], srcPicture.pBuffer[srcVBufferIndex]);
    } else if (SRC_PICTURE_FORMAT == PixelFormatInterleaved8BitBGRA) {
        const uint32_t pixelIndex = lumaCoords.y * SRC_PICTURE_STRIDE + lumaCoords.x * 4;
        i32vec3 rgbSamples = i32vec3(srcPicture.pBuffer[pixelIndex + 2], srcPicture.pBuffer[pixelIndex + 1], srcPicture.pBuffer[pixelIndex + 0]);
        return rgbToYUV(rgbSamples);
    } else if (SRC_PICTURE_FORMAT == PixelFormatInterleaved8BitRGBA) {
        const uint32_t pixelIndex = lumaCoords.y * SRC_PICTURE_STRIDE + lumaCoords.x * 4;
        i32vec3 rgbSamples = i32vec3(srcPicture.pBuffer[pixelIndex + 0], srcPicture.pBuffer[pixelIndex + 1], srcPicture.pBuffer[pixelIndex + 2]);
        return rgbToYUV(rgbSamples);
    }
}

// Nearest sampling

uvec2 getNearestBlockCoords(const vec2 normalizedBlockCoords) {
    vec2 srcChromaBlockCount = vec2(float(SRC_PICTURE_BLOCK_COUNT_X), float(SRC_PICTURE_BLOCK_COUNT_Y));
    vec2 readBlockCoords = round(normalizedBlockCoords * srcChromaBlockCount);
    readBlockCoords = clamp(readBlockCoords, vec2(0.0,0.0), srcChromaBlockCount - vec2(1.0));
    return uvec2(readBlockCoords);
}

YUV420Block read420SampleNearest(const uvec2 blockCoords) {
    const vec2 normalizedBlockCoords = vec2(float(blockCoords.x) / float(DST_PICTURE_BLOCK_COUNT_X), float(blockCoords.y) / float(DST_PICTURE_BLOCK_COUNT_Y));
    return read420Sample(getNearestBlockCoords(normalizedBlockCoords));
}

YUV422Block read422SampleNearest(const uvec2 blockCoords) {
    const vec2 normalizedBlockCoords = vec2(float(blockCoords.x) / float(DST_PICTURE_BLOCK_COUNT_X), float(blockCoords.y) / float(DST_PICTURE_BLOCK_COUNT_Y));
    return read422Sample(getNearestBlockCoords(normalizedBlockCoords));
}

YUV444Block read444SampleNearest(const uvec2 blockCoords) {
    const vec2 normalizedBlockCoords = vec2(float(blockCoords.x) / float(DST_PICTURE_BLOCK_COUNT_X), float(blockCoords.y) / float(DST_PICTURE_BLOCK_COUNT_Y));
    return read444Sample(getNearestBlockCoords(normalizedBlockCoords));
}

// Bilinear sampling

YUV420Block read420Bilinear(const uvec2 blockCoords) {
    YUV420Block result;
    const uvec2 srcImageSize = uvec2(SRC_PICTURE_WIDTH, SRC_PICTURE_HEIGHT);
    const uvec2 dstImageSize = uvec2(DST_PICTURE_WIDTH, DST_PICTURE_HEIGHT);
    u32vec3[4 * 4] sampledPixels;
    [[unroll]]
    for (int i = 0; i < BlockSize.x; i += 1) {
        [[unroll]]
        for (int j = 0; j < BlockSize.y; j += 1) {
            const uvec2 dstLumaCoords = blockCoords * BlockSize + uvec2(i,j);
            const vec2 pixelSize = vec2(1.0) / vec2(dstImageSize);
            const vec2 normalizedLumaCoords = dstLumaCoords / vec2(dstImageSize);
            const vec2 srcLumaCoords = normalizedLumaCoords * vec2(srcImageSize);
            const vec2 pixelDistance = fract(normalizedLumaCoords * srcImageSize);

            const vec2 topLeftCoord = srcLumaCoords;
            const vec2 topRightCoord = srcLumaCoords + vec2(pixelSize.x, 0.0);
            const vec2 bottomLeftCoord = srcLumaCoords + vec2(0.0, pixelSize.y);
            const vec2 bottomRightCoord = srcLumaCoords + pixelSize;

            const uint blockIndex = 4 * ((j * BlockSize.y) + i);
            sampledPixels[blockIndex] = readPixel(uvec2(topLeftCoord));
            sampledPixels[blockIndex + 1] = readPixel(uvec2(topRightCoord));
            sampledPixels[blockIndex + 2] = readPixel(uvec2(bottomLeftCoord));
            sampledPixels[blockIndex + 3] = readPixel(uvec2(bottomRightCoord));

            // Interpolate and write Y sample
            const u32vec3 topLeftPixel = sampledPixels[blockIndex];
            const u32vec3 topRightPixel = sampledPixels[blockIndex + 1];
            const u32vec3 bottomLeftPixel = sampledPixels[blockIndex + 2];
            const u32vec3 bottomRightPixel = sampledPixels[blockIndex + 3];
            {
                vec4 ySamples = vec4(
                    float(topLeftPixel.x),
                    float(topRightPixel.x),
                    float(bottomLeftPixel.x),
                    float(bottomRightPixel.x)
                );
                const float topXInterp = mix(ySamples.x, ySamples.y, pixelDistance.x);
                const float bottomXInterp = mix(ySamples.z, ySamples.w, pixelDistance.x);
                result.ySamples[j * BlockSize.y + i] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
            }
        }
    }

    // Interpolate chroma samples
    const u32vec3 topLeftPixel = sampledPixels[0];
    const u32vec3 topRightPixel = sampledPixels[1];
    const u32vec3 bottomLeftPixel = sampledPixels[2];
    const u32vec3 bottomRightPixel = sampledPixels[3];

    const uvec2 dstLumaCoords = blockCoords * BlockSize;
    const vec2 normalizedLumaCoords = dstLumaCoords / vec2(dstImageSize);
    const vec2 pixelDistance = fract(normalizedLumaCoords * srcImageSize);
    // Interpolate and write U sample
    {
        vec4 uSamples = vec4(
            float(topLeftPixel.y),
            float(topRightPixel.y),
            float(bottomLeftPixel.y),
            float(bottomRightPixel.y)
        );
        const float topXInterp = mix(uSamples.x, uSamples.y, pixelDistance.x);
        const float bottomXInterp = mix(uSamples.z, uSamples.w, pixelDistance.x);
        result.uSample = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
    }

    // Interpolate and write V sample
    {
        vec4 vSamples = vec4(
            float(topLeftPixel.z),
            float(topRightPixel.z),
            float(bottomLeftPixel.z),
            float(bottomRightPixel.z)
        );
        const float topXInterp = mix(vSamples.x, vSamples.y, pixelDistance.x);
        const float bottomXInterp = mix(vSamples.z, vSamples.w, pixelDistance.x);
        result.vSample = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
    }

    return result;
}

YUV422Block read422Bilinear(const uvec2 blockCoords) {
    YUV422Block result;
    const uvec2 srcImageSize = uvec2(SRC_PICTURE_WIDTH, SRC_PICTURE_HEIGHT);
    const uvec2 dstImageSize = uvec2(DST_PICTURE_WIDTH, DST_PICTURE_HEIGHT);
    u32vec3[4 * 4] sampledPixels;
    [[unroll]]
    for (int i = 0; i < BlockSize.x; i += 1) {
        [[unroll]]
        for (int j = 0; j < BlockSize.y; j += 1) {
            const uvec2 dstLumaCoords = blockCoords * BlockSize + uvec2(i,j);
            const vec2 pixelSize = vec2(1.0) / vec2(dstImageSize);
            const vec2 normalizedLumaCoords = dstLumaCoords / vec2(dstImageSize);
            const vec2 srcLumaCoords = normalizedLumaCoords * vec2(srcImageSize);
            const vec2 pixelDistance = fract(normalizedLumaCoords * srcImageSize);

            const vec2 topLeftCoord = srcLumaCoords;
            const vec2 topRightCoord = srcLumaCoords + vec2(pixelSize.x, 0.0);
            const vec2 bottomLeftCoord = srcLumaCoords + vec2(0.0, pixelSize.y);
            const vec2 bottomRightCoord = srcLumaCoords + pixelSize;

            const uint blockIndex = 4 * ((j * BlockSize.y) + i);
            sampledPixels[blockIndex] = readPixel(uvec2(topLeftCoord));
            sampledPixels[blockIndex + 1] = readPixel(uvec2(topRightCoord));
            sampledPixels[blockIndex + 2] = readPixel(uvec2(bottomLeftCoord));
            sampledPixels[blockIndex + 3] = readPixel(uvec2(bottomRightCoord));

            const u32vec3 topLeftPixel = sampledPixels[blockIndex];
            const u32vec3 topRightPixel = sampledPixels[blockIndex + 1];
            const u32vec3 bottomLeftPixel = sampledPixels[blockIndex + 2];
            const u32vec3 bottomRightPixel = sampledPixels[blockIndex + 3];
            // Interpolate and write Y sample
            {
                vec4 ySamples = vec4(
                    float(topLeftPixel.x),
                    float(topRightPixel.x),
                    float(bottomLeftPixel.x),
                    float(bottomRightPixel.x)
                );
                const float topXInterp = mix(ySamples.x, ySamples.y, pixelDistance.x);
                const float bottomXInterp = mix(ySamples.z, ySamples.w, pixelDistance.x);
                result.ySamples[j * BlockSize.y + i] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
            }
        }
    }

    [[unroll]]
    for (int j = 0; j < BlockSize.y; j += 1) {
        const uvec2 dstLumaCoords = blockCoords * BlockSize + uvec2(0,j);
        const vec2 normalizedLumaCoords = dstLumaCoords / vec2(dstImageSize);
        const vec2 pixelDistance = fract(normalizedLumaCoords * srcImageSize);

        const uint blockIndex = 4 * (j * BlockSize.y);
        const u32vec3 topLeftPixel = sampledPixels[blockIndex];
        const u32vec3 topRightPixel = sampledPixels[blockIndex + 1];
        const u32vec3 bottomLeftPixel = sampledPixels[blockIndex + 2];
        const u32vec3 bottomRightPixel = sampledPixels[blockIndex + 3];
        // Interpolate and write U sample
        {
            vec4 uSamples = vec4(
                float(topLeftPixel.y),
                float(topRightPixel.y),
                float(bottomLeftPixel.y),
                float(bottomRightPixel.y)
            );
            const float topXInterp = mix(uSamples.x, uSamples.y, pixelDistance.x);
            const float bottomXInterp = mix(uSamples.z, uSamples.w, pixelDistance.x);
            result.uSamples[j] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
        }

        // Interpolate and write V sample
        {
            vec4 vSamples = vec4(
                float(topLeftPixel.z),
                float(topRightPixel.z),
                float(bottomLeftPixel.z),
                float(bottomRightPixel.z)
            );
            const float topXInterp = mix(vSamples.x, vSamples.y, pixelDistance.x);
            const float bottomXInterp = mix(vSamples.z, vSamples.w, pixelDistance.x);
            result.vSamples[j] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
        }
    }
    return result;
}

YUV444Block read444Bilinear(const uvec2 blockCoords) {
    YUV444Block result;
    const uvec2 srcImageSize = uvec2(SRC_PICTURE_WIDTH, SRC_PICTURE_HEIGHT);
    const uvec2 dstImageSize = uvec2(DST_PICTURE_WIDTH, DST_PICTURE_HEIGHT);
    [[unroll]]
    for (int i = 0; i < BlockSize.x; i += 1) {
        [[unroll]]
        for (int j = 0; j < BlockSize.y; j += 1) {
            const uvec2 dstLumaCoords = blockCoords * BlockSize + uvec2(i,j);
            const vec2 pixelSize = vec2(1.0) / vec2(dstImageSize);
            const vec2 normalizedLumaCoords = dstLumaCoords / vec2(dstImageSize);
            const vec2 srcLumaCoords = normalizedLumaCoords * vec2(srcImageSize);
            const vec2 pixelDistance = fract(normalizedLumaCoords * srcImageSize);

            const vec2 topLeftCoord = srcLumaCoords;
            const vec2 topRightCoord = srcLumaCoords + vec2(pixelSize.x, 0.0);
            const vec2 bottomLeftCoord = srcLumaCoords + vec2(0.0, pixelSize.y);
            const vec2 bottomRightCoord = srcLumaCoords + pixelSize;

            u32vec3 topLeftPixel = readPixel(uvec2(topLeftCoord));
            u32vec3 topRightPixel = readPixel(uvec2(topRightCoord));
            u32vec3 bottomLeftPixel = readPixel(uvec2(bottomLeftCoord));
            u32vec3 bottomRightPixel = readPixel(uvec2(bottomRightCoord));
            
            // Interpolate and write Y sample
            {
                vec4 ySamples = vec4(
                    float(topLeftPixel.x),
                    float(topRightPixel.x),
                    float(bottomLeftPixel.x),
                    float(bottomRightPixel.x)
                );
                const float topXInterp = mix(ySamples.x, ySamples.y, pixelDistance.x);
                const float bottomXInterp = mix(ySamples.z, ySamples.w, pixelDistance.x);
                result.ySamples[j * BlockSize.y + i] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
            }

            // Interpolate and write U sample
            {
                vec4 uSamples = vec4(
                    float(topLeftPixel.y),
                    float(topRightPixel.y),
                    float(bottomLeftPixel.y),
                    float(bottomRightPixel.y)
                );
                const float topXInterp = mix(uSamples.x, uSamples.y, pixelDistance.x);
                const float bottomXInterp = mix(uSamples.z, uSamples.w, pixelDistance.x);
                result.uSamples[j * BlockSize.y + i] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
            }

            // Interpolate and write V sample
            {
                vec4 vSamples = vec4(
                    float(topLeftPixel.z),
                    float(topRightPixel.z),
                    float(bottomLeftPixel.z),
                    float(bottomRightPixel.z)
                );
                const float topXInterp = mix(vSamples.x, vSamples.y, pixelDistance.x);
                const float bottomXInterp = mix(vSamples.z, vSamples.w, pixelDistance.x);
                result.vSamples[j * BlockSize.y + i] = uint32_t(round(mix(topXInterp, bottomXInterp, pixelDistance.y)));
            }
        }
    }
    return result;
}

// Write functions, to store into the result buffer
// For now, exclusively writes to YUV planar buffers

void write420Sample(const uvec2 blockCoords, in YUV420Block resultBlock) {
    [[unroll]]
    for (uint y = 0; y < 2; y += 1) {
        const uvec2 lumaCoords = uvec2(blockCoords.x * 2, blockCoords.y * 2 + y);
        if (lumaCoords.x < DST_PICTURE_WIDTH && lumaCoords.y < DST_PICTURE_HEIGHT) {
            const uint dstYBufferIndex = lumaCoords.y * DST_PICTURE_STRIDE + lumaCoords.x;
            dstPicture.pBuffer[dstYBufferIndex] = uint8_t(resultBlock.ySamples[y * 2]);
            dstPicture.pBuffer[dstYBufferIndex + 1] = uint8_t(resultBlock.ySamples[y * 2 + 1]);
        }
    }

    const uvec2 chromaCoords = uvec2(blockCoords.x, blockCoords.y);
    if (chromaCoords.x < DST_PICTURE_CHROMA_WIDTH && chromaCoords.y < DST_PICTURE_CHROMA_HEIGHT) {
        const uint dstUBufferIndex = DST_PICTURE_U_OFFSET + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE + chromaCoords.x;
        dstPicture.pBuffer[dstUBufferIndex] = uint8_t(resultBlock.uSample);

        const uint dstVBufferIndex = DST_PICTURE_V_OFFSET + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE + chromaCoords.x;
        dstPicture.pBuffer[dstVBufferIndex] = uint8_t(resultBlock.vSample);
    }
}

void write422Sample(const uvec2 blockCoords, in YUV422Block resultBlock) {
    // Only planar format for now
    [[unroll]]
    for (uint y = 0; y < 2; y += 1) {
        const uvec2 lumaCoords = uvec2(blockCoords.x * 2, blockCoords.y * 2 + y);
        if (lumaCoords.x < DST_PICTURE_WIDTH && lumaCoords.y < DST_PICTURE_HEIGHT) {
            const uint dstYBufferIndex = lumaCoords.y * DST_PICTURE_STRIDE + lumaCoords.x;
            dstPicture.pBuffer[dstYBufferIndex] = uint8_t(resultBlock.ySamples[y * 2]);
            dstPicture.pBuffer[dstYBufferIndex + 1] = uint8_t(resultBlock.ySamples[y * 2 + 1]);
        }
    }

    [[unroll]]
    for (uint y = 0; y < 2; y += 1) {
        const uvec2 chromaCoords = uvec2(blockCoords.x, blockCoords.y * 2 + y);
        if (chromaCoords.x < DST_PICTURE_CHROMA_WIDTH && chromaCoords.y < DST_PICTURE_CHROMA_HEIGHT) {
            const uint dstUBufferIndex = DST_PICTURE_U_OFFSET + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE + chromaCoords.x;
            dstPicture.pBuffer[dstUBufferIndex] = uint8_t(resultBlock.uSamples[y]);
        }
    }

    [[unroll]]
    for (uint y = 0; y < 2; y += 1) {
        const uvec2 chromaCoords = uvec2(blockCoords.x, blockCoords.y * 2 + y);
        if (chromaCoords.x < DST_PICTURE_CHROMA_WIDTH && chromaCoords.y < DST_PICTURE_CHROMA_HEIGHT) {
            const uint dstVBufferIndex = DST_PICTURE_V_OFFSET + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE + chromaCoords.x;
            dstPicture.pBuffer[dstVBufferIndex] = uint8_t(resultBlock.vSamples[y]);
        }
    }
}

void write444Sample(const uvec2 blockCoords, in YUV444Block resultBlock) {
    // Only planar format for now
    [[unroll]]
    for (int i = 0; i < 2; i += 1) {
        [[unroll]]
        for (int j = 0; j < 2; j += 1) {
            uvec2 lumaCoords = uvec2(blockCoords.x * 2 + i, blockCoords.y * 2 + j);
            if (lumaCoords.x < DST_PICTURE_WIDTH && lumaCoords.y < DST_PICTURE_HEIGHT) {
                const uint dstYBufferIndex = lumaCoords.y * DST_PICTURE_STRIDE + lumaCoords.x;
                dstPicture.pBuffer[dstYBufferIndex] = uint8_t(resultBlock.ySamples[j * 2 + i]);
            }
        }
    }

    [[unroll]]
    for (int i = 0; i < 2; i += 1) {
        [[unroll]]
        for (int j = 0; j < 2; j += 1) {
            const uvec2 chromaCoords = uvec2(blockCoords.x * 2 + i, blockCoords.y * 2 + j);
            if (chromaCoords.x < DST_PICTURE_WIDTH && chromaCoords.y < DST_PICTURE_HEIGHT) {
                const uint dstUBufferIndex = DST_PICTURE_U_OFFSET + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE + chromaCoords.x;
                dstPicture.pBuffer[dstUBufferIndex] = uint8_t(resultBlock.uSamples[j * 2 + i]);
            }
        }
    }

    [[unroll]]
    for (int i = 0; i < 2; i += 1) {
        [[unroll]]
        for (int j = 0; j < 2; j += 1) {
            const uvec2 chromaCoords = uvec2(blockCoords.x * 2 + i, blockCoords.y * 2 + j);
            if (chromaCoords.x < DST_PICTURE_WIDTH && chromaCoords.y < DST_PICTURE_HEIGHT) {
                const uint dstVBufferIndex = DST_PICTURE_V_OFFSET + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE + chromaCoords.x;
                dstPicture.pBuffer[dstVBufferIndex] = uint8_t(resultBlock.vSamples[j * 2 + i]);
            }
        }
    }
}

/*
    Workflow:
        -> The shader will read (and convert) any format passed to it. Meaning results always are in the target subsample format. Regardless of input.
            -> If the source and target subsampling doesn't match, the shader will read as many samples as necessary to go from source subsample -> dst subsample
                -> The function read422Sample will convert whatever the current input format is to SubsampleType
                -> It will rely on read422From422 and friends to get the values out of the buffer using the actual source type
                -> When the subsample method doesn't match it will convert it (example: going from RGB to 444 by converting via YUV matrix)
            -> Some filtering may be used by calling read422SampleNearest and friends, if necessary
                -> When using bilinear filtering, custom read methods will be used (see the readPixel function)
        -> After everything is read, the shader will now have a block of samples in the same subsampling method as the dest. buffer
        -> The shader will now write into the dst buffer depending on its format (see write420Sample, write422Sample, etc)

        Examples:
            - No subsampling conversion:
                read422SampleNearest()
                    read422Sample()
                        read422SampleFrom422Buffer() 
                write422Sample()
            - From 420 buffer to 422 buffer:
                read422SampleBilinear()
                    readPixel() <- x16 times
                    pixels are interpolated
                write422Sample()
*/
void main() {
    const uvec2 blockCoords = gl_GlobalInvocationID.xy;
    if (DST_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_RGB) {
        // TODO
    } else if (DST_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV420) {
        YUV420Block resultBlock;
        if (needsScaling) {
            resultBlock = read420Bilinear(blockCoords);
        } else {
            resultBlock = read420Sample(blockCoords);
        }
        write420Sample(blockCoords, resultBlock);
    } else if (DST_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV422) {
        YUV422Block resultBlock;
        if (needsScaling) {
           resultBlock = read422Bilinear(blockCoords);
        } else {
            resultBlock = read422Sample(blockCoords);
        }
        write422Sample(blockCoords, resultBlock);
    } else if (DST_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV444) {
        YUV444Block resultBlock;
        if (needsScaling) {
            resultBlock = read444Bilinear(blockCoords);
        } else {
            resultBlock = read444Sample(blockCoords);
        }
        write444Sample(blockCoords, resultBlock);
    }
}