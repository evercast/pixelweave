#version 450

#extension GL_EXT_shader_explicit_arithmetic_types : require
#extension GL_EXT_shader_explicit_arithmetic_types_int8 : require
#extension GL_EXT_shader_16bit_storage : require
#extension GL_EXT_shader_8bit_storage : require
#extension GL_EXT_scalar_block_layout : require

#define LOCAL_WORKGROUP_SIZE_X 16
#define LOCAL_WORKGROUP_SIZE_Y 16

// See PixelFormat.h
const uint PixelFormatInterleaved8BitUYVY = 0;
const uint PixelFormatInterleved8BitBGRA = 1;
const uint PixelFormatInterleaved8BitRGBA = 2;
const uint PixelFormatPlanar8Bit420 = 3;
const uint PixelFormatPlanar8Bit422 = 4;
const uint PixelFormatPlanar8Bit444 = 5;
const uint PixelFormatPlanar8Bit420YV12 = 6;
const uint PixelFormatPlanar8Bit422NV12 = 7;

const uint SUBSAMPLE_TYPE_RGB = 0;
const uint SUBSAMPLE_TYPE_YUV420 = 1;
const uint SUBSAMPLE_TYPE_YUV422 = 2;
const uint SUBSAMPLE_TYPE_YUV444 = 3;

// Source picture properties (specialization constants for optimization)
layout (constant_id = 0) const uint SRC_PICTURE_WIDTH = 0;
layout (constant_id = 1) const uint SRC_PICTURE_HEIGHT = 0;
layout (constant_id = 2) const uint SRC_PICTURE_STRIDE = 0; // Luma stride in planar formats
layout (constant_id = 3) const uint SRC_PICTURE_CHROMA_WIDTH = 0;
layout (constant_id = 4) const uint SRC_PICTURE_CHROMA_HEIGHT = 0;
layout (constant_id = 5) const uint SRC_PICTURE_CHROMA_STRIDE = 0;
layout (constant_id = 6) const uint SRC_PICTURE_FORMAT = 0;
layout (constant_id = 7) const uint SRC_PICTURE_SUBSAMPLE_TYPE = 0;
layout (constant_id = 8) const uint SRC_PICTURE_U_OFFSET = 0;
layout (constant_id = 9) const uint SRC_PICTURE_V_OFFSET = 0;

layout (constant_id = 10) const uint DST_PICTURE_WIDTH = 0;
layout (constant_id = 11) const uint DST_PICTURE_HEIGHT = 0;
layout (constant_id = 12) const uint DST_PICTURE_STRIDE = 0; // Luma stride in planar formats
layout (constant_id = 13) const uint DST_PICTURE_CHROMA_WIDTH = 0;
layout (constant_id = 14) const uint DST_PICTURE_CHROMA_HEIGHT = 0;
layout (constant_id = 15) const uint DST_PICTURE_CHROMA_STRIDE = 0;
layout (constant_id = 16) const uint DST_PICTURE_FORMAT = 0;
layout (constant_id = 17) const uint DST_PICTURE_SUBSAMPLE_TYPE = 0;
layout (constant_id = 18) const uint DST_PICTURE_U_OFFSET = 0;
layout (constant_id = 19) const uint DST_PICTURE_V_OFFSET = 0;

const uint SRC_PICTURE_BLOCK_COUNT_X = (SRC_PICTURE_WIDTH + 1) / 2;
const uint SRC_PICTURE_BLOCK_COUNT_Y = (SRC_PICTURE_HEIGHT + 1) / 2;
const uint DST_PICTURE_BLOCK_COUNT_X = (DST_PICTURE_WIDTH + 1) / 2;
const uint DST_PICTURE_BLOCK_COUNT_Y = (DST_PICTURE_HEIGHT + 1) / 2;

const bool needsScaling = SRC_PICTURE_WIDTH != DST_PICTURE_WIDTH || SRC_PICTURE_HEIGHT != DST_PICTURE_HEIGHT;

layout(local_size_x = LOCAL_WORKGROUP_SIZE_X, local_size_y = LOCAL_WORKGROUP_SIZE_Y) in;

layout(scalar, set = 0, binding = 0) readonly buffer SrcPicture
{
    uint8_t[] pBuffer;
}
srcPicture;

layout(scalar, set = 0, binding = 1) buffer DstPicture
{
    uint8_t[] pBuffer;
}
dstPicture;

struct YUV422Block {
    uint32_t[4] ySamples; // Top left, top right, bottom left, bottom right
    uint32_t[2] uSamples; // Top, bottom
    uint32_t[2] vSamples; // Top, bottom
};

// Read functions, to retrieve and convert samples
YUV422Block read422SampleFrom422Buffer(const uvec2 blockCoords) {
    YUV422Block resultBlock;
    if (SRC_PICTURE_FORMAT == PixelFormatInterleaved8BitUYVY) {
        for (uint y = 0; y < 2; y += 1) {
            uvec2 lumaCoords = uvec2(blockCoords.x * 2, blockCoords.y * 2 + y);
            lumaCoords = clamp(lumaCoords, uvec2(0), uvec2(SRC_PICTURE_WIDTH - 1, SRC_PICTURE_HEIGHT - 1));
            const uint srcBytesPerSample = 4;
            const uint srcBufferIndex = lumaCoords.y * SRC_PICTURE_STRIDE + (lumaCoords.x * srcBytesPerSample / 2);
            resultBlock.uSamples[y] = srcPicture.pBuffer[srcBufferIndex + 0];
            resultBlock.ySamples[y * 2] = srcPicture.pBuffer[srcBufferIndex + 1];
            resultBlock.vSamples[y] = srcPicture.pBuffer[srcBufferIndex + 2];
            resultBlock.ySamples[y * 2 + 1] = srcPicture.pBuffer[srcBufferIndex + 3];
        }
    }
    return resultBlock;
}

YUV422Block read422Sample(const uvec2 blockCoords) {
    YUV422Block resultBlock;
    if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_RGB) {
        // TODO
    } else if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV420) {
        // TODO
    } else if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV422) {
        return read422SampleFrom422Buffer(blockCoords);
    } else if (SRC_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV444) {
        // TODO
    }
    return resultBlock;
}

YUV422Block read422SampleNearest(const vec2 normalizedBlockCoords) {
    vec2 srcChromaBlockCount = vec2(float(SRC_PICTURE_BLOCK_COUNT_X), float(SRC_PICTURE_BLOCK_COUNT_Y));
    vec2 readBlockCoords = floor(normalizedBlockCoords * srcChromaBlockCount + vec2(0.5));
    readBlockCoords = clamp(readBlockCoords, vec2(0.0,0.0), srcChromaBlockCount - vec2(1.0));
    return read422Sample(uvec2(readBlockCoords));
}

// Write functions, to store into the result buffer
void write422Sample(const uvec2 blockCoords, in YUV422Block resultBlock) {
    // Only planar format for now
    for (uint y = 0; y < 2; y += 1) {
        const uvec2 lumaCoords = uvec2(blockCoords.x * 2, blockCoords.y * 2 + y);
        if (lumaCoords.x < DST_PICTURE_WIDTH && lumaCoords.y < DST_PICTURE_HEIGHT) {
            const uint dstYBufferIndex = lumaCoords.y * DST_PICTURE_STRIDE + lumaCoords.x;
            dstPicture.pBuffer[dstYBufferIndex] = uint8_t(resultBlock.ySamples[y * 2]);
            dstPicture.pBuffer[dstYBufferIndex + 1] = uint8_t(resultBlock.ySamples[y * 2 + 1]);
        }
    }

    const uint baseUIndex = DST_PICTURE_U_OFFSET;
    for (uint y = 0; y < 2; y += 1) {
        const uvec2 chromaCoords = uvec2(blockCoords.x, blockCoords.y * 2 + y);
        if (chromaCoords.x < DST_PICTURE_CHROMA_WIDTH && chromaCoords.y < DST_PICTURE_CHROMA_HEIGHT) {
            const uint dstUBufferIndex = baseUIndex + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE + chromaCoords.x;
            dstPicture.pBuffer[dstUBufferIndex] = uint8_t(resultBlock.uSamples[y]);
        }
    }

    const uint baseVIndex = DST_PICTURE_V_OFFSET;
    for (uint y = 0; y < 2; y += 1) {
        const uvec2 chromaCoords = uvec2(blockCoords.x, blockCoords.y * 2 + y);
        if (chromaCoords.x < DST_PICTURE_CHROMA_WIDTH && chromaCoords.y < DST_PICTURE_CHROMA_HEIGHT) {
            const uint dstVBufferIndex = baseVIndex + chromaCoords.y * DST_PICTURE_CHROMA_STRIDE + chromaCoords.x;
            dstPicture.pBuffer[dstVBufferIndex] = uint8_t(resultBlock.vSamples[y]);
        }
    }
}

/*
    Workflow:
        -> The shader will read (and convert) any format passed to it. Meaning results always are in the target subsample format. Regardless of input.
            -> If the source and target subsampling doesn't match, the shader will read as many samples as necessary to go from source subsample -> dst subsample
                -> The function read422Sample will convert whatever the current input format is to SubsampleType
                -> It will rely on read422From422 and friends to get the values out of the buffer using the actual source type
                -> When the subsample method doesn't match it will convert it (example: going from RGB to 444 by converting via YUV matrix)
            -> Some filtering may be used by calling read422SampleNearest and friends, if necessary
        -> After everything is read, the shader will now have a block of samples in the same subsampling method as the dest. buffer
        -> The shader will now write into the dst buffer depending on its format (see write420Sample, write422Sample, etc)

        Examples:
            No subsampling conversion:
                read422SampleNearest()
                    read422Sample()
                        read422SampleFrom422Buffer() 
                write422Sample()
            From 420 buffer to 422 buffer:
                read422SampleNearest()
                    read422Sample()
                        read420SampleFrom420Buffer()
                        convert420SampleTo422Sample()
                write422Sample()
*/
void main() {
    const uvec2 blockCoords = gl_GlobalInvocationID.xy;
    // Read UYVY samples from source buffer
    if (DST_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_RGB) {
        // TODO
    } else if (DST_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV420) {
        // TODO
    } else if (DST_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV422) {
        YUV422Block resultBlock;
        if (needsScaling) {
            vec2 normalizedBlockCoords = vec2(float(blockCoords.x) / float(DST_PICTURE_BLOCK_COUNT_X), float(blockCoords.y) / float(DST_PICTURE_BLOCK_COUNT_Y));
            resultBlock = read422SampleNearest(normalizedBlockCoords);
        } else {
            resultBlock = read422Sample(blockCoords);
        }
        write422Sample(blockCoords, resultBlock);
    } else if (DST_PICTURE_SUBSAMPLE_TYPE == SUBSAMPLE_TYPE_YUV444) {
        // TODO
    }
}